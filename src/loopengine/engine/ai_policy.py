"""AI-driven policy for simulation agents using LLM-based behavior generation.

This module provides AIPolicy, a callable that integrates AIBehaviorEngine
with the simulation's policy interface. Agents can use AIPolicy as their
policy function to have their decisions generated by an LLM.
"""

from __future__ import annotations

import logging
import uuid
from typing import TYPE_CHECKING, Any

from loopengine.behaviors import (
    AgentContext,
    AIBehaviorEngine,
    BehaviorResponse,
    DomainContext,
)
from loopengine.model.particle import Particle

if TYPE_CHECKING:
    from loopengine.model.agent import Agent
    from loopengine.model.world import World

logger = logging.getLogger(__name__)


class ActionConverter:
    """Converts BehaviorResponse actions to Particle outputs.

    Maps LLM-generated actions (like "make_sandwich", "send_directive")
    to properly routed Particle objects.
    """

    def convert(
        self,
        response: BehaviorResponse,
        agent: Agent,
        world: World,
    ) -> list[Particle]:
        """Convert a BehaviorResponse to a list of Particles.

        Args:
            response: The LLM-generated behavior response.
            agent: The agent performing the action.
            world: The world context for routing.

        Returns:
            List of Particle objects representing the action outputs.
        """
        action = response.action.lower()
        params = response.parameters

        # Handle common action patterns
        if action in ("idle", "wait", "observe", "do_nothing"):
            return []

        # Check for explicit particle creation params
        if "particle_type" in params and "dest_id" in params:
            return [self._create_explicit_particle(response, agent, world)]

        # Route based on action type patterns
        if action.startswith("send_") or action.startswith("emit_"):
            return self._handle_send_action(action, params, agent, world)

        if action in ("make_sandwich", "prepare_order", "create_product"):
            return self._handle_production_action(action, params, agent, world)

        if action in ("create_ticket", "create_order", "take_order"):
            return self._handle_ticket_action(action, params, agent, world)

        if action in ("serve_customer", "deliver", "complete_order"):
            return self._handle_serve_action(action, params, agent, world)

        if action in ("report_status", "status_report"):
            return self._handle_report_action(action, params, agent, world)

        if action in ("issue_directive", "send_directive", "direct"):
            return self._handle_directive_action(action, params, agent, world)

        # Generic action: create particle with action as type
        return self._handle_generic_action(action, params, agent, world)

    def _create_explicit_particle(
        self,
        response: BehaviorResponse,
        agent: Agent,
        world: World,
    ) -> Particle:
        """Create a particle from explicit parameters."""
        params = response.parameters
        dest_id = params.get("dest_id", "external")
        link_id = self._find_link(agent.id, dest_id, world)

        return Particle(
            id=str(uuid.uuid4()),
            particle_type=params.get("particle_type", response.action),
            payload=params.get("payload", {}),
            source_id=agent.id,
            dest_id=dest_id,
            link_id=link_id,
        )

    def _handle_send_action(
        self,
        action: str,
        params: dict[str, Any],
        agent: Agent,
        world: World,
    ) -> list[Particle]:
        """Handle send_* actions."""
        # Extract what to send from action name (e.g., send_sandwich -> sandwich)
        particle_type = action.replace("send_", "").replace("emit_", "")
        dest_id = params.get("dest_id", params.get("to", "external"))
        link_id = self._find_link(agent.id, dest_id, world)

        return [
            Particle(
                id=str(uuid.uuid4()),
                particle_type=particle_type,
                payload=params.get("payload", params),
                source_id=agent.id,
                dest_id=dest_id,
                link_id=link_id,
            )
        ]

    def _handle_production_action(
        self,
        action: str,
        params: dict[str, Any],
        agent: Agent,
        world: World,
    ) -> list[Particle]:
        """Handle production actions like make_sandwich."""
        # Find service link to recipient (usually cashier)
        dest_id = params.get("dest_id", self._find_service_recipient(agent, world))
        link_id = self._find_link(agent.id, dest_id, world)

        return [
            Particle(
                id=str(uuid.uuid4()),
                particle_type="finished_sandwich" if "sandwich" in action else "product",
                payload={
                    "order": params.get("order", {}),
                    "quality": params.get("quality", 0.8),
                    "maker": agent.id,
                },
                source_id=agent.id,
                dest_id=dest_id,
                link_id=link_id,
            )
        ]

    def _handle_ticket_action(
        self,
        action: str,
        params: dict[str, Any],
        agent: Agent,
        world: World,
    ) -> list[Particle]:
        """Handle ticket/order creation actions."""
        dest_id = params.get("dest_id", self._find_service_recipient(agent, world))
        link_id = self._find_link(agent.id, dest_id, world)

        return [
            Particle(
                id=str(uuid.uuid4()),
                particle_type="order_ticket",
                payload=params.get("order", params),
                source_id=agent.id,
                dest_id=dest_id,
                link_id=link_id,
            )
        ]

    def _handle_serve_action(
        self,
        action: str,
        params: dict[str, Any],
        agent: Agent,
        world: World,
    ) -> list[Particle]:
        """Handle customer serving actions."""
        return [
            Particle(
                id=str(uuid.uuid4()),
                particle_type="served_customer",
                payload=params,
                source_id=agent.id,
                dest_id="external",
                link_id="",
            )
        ]

    def _handle_report_action(
        self,
        action: str,
        params: dict[str, Any],
        agent: Agent,
        world: World,
    ) -> list[Particle]:
        """Handle status/revenue report actions."""
        # Find hierarchical superior
        dest_id = params.get("dest_id", self._find_superior(agent, world))
        link_id = self._find_link(agent.id, dest_id, world)

        return [
            Particle(
                id=str(uuid.uuid4()),
                particle_type=params.get("report_type", "status_report"),
                payload=params,
                source_id=agent.id,
                dest_id=dest_id,
                link_id=link_id,
            )
        ]

    def _handle_directive_action(
        self,
        action: str,
        params: dict[str, Any],
        agent: Agent,
        world: World,
    ) -> list[Particle]:
        """Handle directive/command actions."""
        dest_id = params.get("dest_id", params.get("to"))
        if not dest_id:
            # Find a subordinate to direct
            dest_id = self._find_subordinate(agent, world)
        link_id = self._find_link(agent.id, dest_id, world)

        return [
            Particle(
                id=str(uuid.uuid4()),
                particle_type="directive",
                payload=params,
                source_id=agent.id,
                dest_id=dest_id,
                link_id=link_id,
            )
        ]

    def _handle_generic_action(
        self,
        action: str,
        params: dict[str, Any],
        agent: Agent,
        world: World,
    ) -> list[Particle]:
        """Handle generic/unknown actions."""
        dest_id = params.get("dest_id", "external")
        link_id = self._find_link(agent.id, dest_id, world) if dest_id != "external" else ""

        return [
            Particle(
                id=str(uuid.uuid4()),
                particle_type=action,
                payload=params,
                source_id=agent.id,
                dest_id=dest_id,
                link_id=link_id,
            )
        ]

    def _find_link(self, source_id: str, dest_id: str, world: World) -> str:
        """Find a link between source and destination."""
        for link in world.links.values():
            if link.source_id == source_id and link.dest_id == dest_id:
                return link.id
        return ""

    def _find_service_recipient(self, agent: Agent, world: World) -> str:
        """Find an agent this agent provides service to."""
        from loopengine.model.link import LinkType

        for link in world.links.values():
            if link.source_id == agent.id and link.link_type == LinkType.SERVICE:
                return link.dest_id
        return "external"

    def _find_superior(self, agent: Agent, world: World) -> str:
        """Find this agent's hierarchical superior."""
        from loopengine.model.link import LinkType

        for link in world.links.values():
            if link.source_id == agent.id and link.link_type == LinkType.HIERARCHICAL:
                return link.dest_id
        return "external"

    def _find_subordinate(self, agent: Agent, world: World) -> str:
        """Find a subordinate of this agent."""
        from loopengine.model.link import LinkType

        for link in world.links.values():
            if link.dest_id != agent.id:
                continue
            # Look for outgoing hierarchical links from this agent
            for out_link in world.links.values():
                if out_link.source_id == agent.id and out_link.link_type == LinkType.HIERARCHICAL:
                    return out_link.dest_id
        return "external"


class AIPolicy:
    """AI-driven policy that generates agent decisions via LLM.

    Wraps AIBehaviorEngine to provide the simulation policy callable interface:
    policy(sensed_inputs, genome, internal_state) -> list[Particle]

    Converts simulation context to LLM-compatible format and translates
    LLM responses back to simulation Particle outputs.

    Attributes:
        engine: The AIBehaviorEngine instance for behavior generation.
        domain: The domain context for LLM prompts.
        converter: Action to Particle converter.
        fallback_policy: Optional fallback when LLM fails.

    Example:
        >>> engine = AIBehaviorEngine()
        >>> domain = DomainContext(
        ...     domain_type="sandwich shop",
        ...     domain_description="A small sandwich shop"
        ... )
        >>> policy = AIPolicy(engine, domain)
        >>> agent.policy = policy.create_callable(agent, world)
    """

    def __init__(
        self,
        engine: AIBehaviorEngine,
        domain: DomainContext,
        converter: ActionConverter | None = None,
        fallback_policy: Any | None = None,
    ) -> None:
        """Initialize the AI policy.

        Args:
            engine: AIBehaviorEngine instance for behavior generation.
            domain: Domain context describing the simulation.
            converter: Optional custom ActionConverter. Uses default if None.
            fallback_policy: Optional fallback policy when LLM fails.
        """
        self.engine = engine
        self.domain = domain
        self.converter = converter or ActionConverter()
        self.fallback_policy = fallback_policy

    def create_callable(
        self,
        agent: Agent,
        world: World,
    ) -> Any:
        """Create a policy callable for a specific agent.

        Returns a callable with signature:
        (sensed_inputs, genome, internal_state) -> list[Particle]

        Args:
            agent: The agent this policy is for.
            world: The world context.

        Returns:
            A callable policy function.
        """

        def policy(
            sensed_inputs: list[Particle],
            genome: dict[str, float],
            internal_state: dict[str, Any],
        ) -> list[Particle]:
            return self._generate_behavior(
                agent=agent,
                world=world,
                sensed_inputs=sensed_inputs,
                genome=genome,
                internal_state=internal_state,
            )

        return policy

    def _generate_behavior(
        self,
        agent: Agent,
        world: World,
        sensed_inputs: list[Particle],
        genome: dict[str, float],
        internal_state: dict[str, Any],
    ) -> list[Particle]:
        """Generate behavior using the AI engine.

        Args:
            agent: The agent making the decision.
            world: The world context.
            sensed_inputs: Particles the agent has sensed.
            genome: Agent's genome traits.
            internal_state: Agent's internal state.

        Returns:
            List of Particle outputs.
        """
        # Build agent context
        agent_context = AgentContext(
            agent_type=agent.role,
            agent_role=self._describe_role(agent),
        )

        # Build simulation context for LLM
        context = self._build_context(
            agent=agent,
            sensed_inputs=sensed_inputs,
            genome=genome,
            internal_state=internal_state,
        )

        try:
            # Query the LLM
            response = self.engine.generate_behavior(
                domain=self.domain,
                agent=agent_context,
                context=context,
            )

            # Store response metadata in internal state for debugging
            internal_state["last_ai_response"] = {
                "action": response.action,
                "parameters": response.parameters,
                "reasoning": response.reasoning,
                "metadata": response.metadata,
            }

            # Convert response to particles
            return self.converter.convert(response, agent, world)

        except Exception as e:
            logger.warning(
                "AI behavior generation failed for agent %s: %s",
                agent.id,
                str(e),
            )

            # Use fallback policy if available
            if self.fallback_policy is not None:
                return self.fallback_policy(sensed_inputs, genome, internal_state)

            # Default fallback: return empty (idle)
            return []

    def _describe_role(self, agent: Agent) -> str:
        """Generate a role description for the agent."""
        labels_str = ", ".join(sorted(agent.labels)) if agent.labels else "general"
        return f"{agent.name} is a {agent.role} with labels: {labels_str}"

    def _build_context(
        self,
        agent: Agent,
        sensed_inputs: list[Particle],
        genome: dict[str, float],
        internal_state: dict[str, Any],
    ) -> dict[str, Any]:
        """Build context dict for LLM prompt.

        Args:
            agent: The agent.
            sensed_inputs: Particles the agent has sensed.
            genome: Agent's genome traits.
            internal_state: Agent's internal state.

        Returns:
            Context dict for LLM prompt.
        """
        # Convert particles to serializable format
        inputs_data = []
        for particle in sensed_inputs:
            inputs_data.append(
                {
                    "type": particle.particle_type,
                    "payload": particle.payload,
                    "from": particle.source_id,
                }
            )

        # Filter internal state to relevant fields
        relevant_state = {
            k: v
            for k, v in internal_state.items()
            if k
            not in (
                "sensed_inputs",
                "oriented_inputs",
                "planned_actions",
                "last_ai_response",
            )
            and not k.startswith("_")
        }

        return {
            "agent_id": agent.id,
            "agent_name": agent.name,
            "sensed_inputs": inputs_data,
            "genome_traits": genome,
            "internal_state": relevant_state,
            "labels": list(agent.labels),
        }


def create_ai_policy_for_agent(
    agent: Agent,
    world: World,
    engine: AIBehaviorEngine,
    domain: DomainContext,
    fallback_policy: Any | None = None,
) -> Any:
    """Create an AI policy callable for a specific agent.

    Convenience function that creates an AIPolicy and returns the
    callable for the given agent.

    Args:
        agent: The agent to create a policy for.
        world: The world context.
        engine: AIBehaviorEngine instance.
        domain: Domain context describing the simulation.
        fallback_policy: Optional fallback when LLM fails.

    Returns:
        A callable policy function with signature:
        (sensed_inputs, genome, internal_state) -> list[Particle]
    """
    ai_policy = AIPolicy(
        engine=engine,
        domain=domain,
        fallback_policy=fallback_policy,
    )
    return ai_policy.create_callable(agent, world)


def enable_ai_behaviors(
    world: World,
    engine: AIBehaviorEngine,
    domain: DomainContext,
    agent_types: set[str] | None = None,
    preserve_fallback: bool = True,
) -> None:
    """Enable AI behaviors for agents in a world.

    Replaces agent policies with AI-driven policies for matching agents.

    Args:
        world: The world containing agents.
        engine: AIBehaviorEngine instance.
        domain: Domain context describing the simulation.
        agent_types: Set of agent roles to enable AI for.
            If None, enables for all agents.
        preserve_fallback: If True, keeps existing policy as fallback.
    """
    for agent in world.agents.values():
        # Check if this agent type should have AI enabled
        if agent_types is not None and agent.role not in agent_types:
            continue

        # Preserve existing policy as fallback if requested
        fallback = agent.policy if preserve_fallback else None

        # Create and assign AI policy
        agent.policy = create_ai_policy_for_agent(
            agent=agent,
            world=world,
            engine=engine,
            domain=domain,
            fallback_policy=fallback,
        )

        # Mark agent as AI-enabled in internal state
        agent.internal_state["ai_enabled"] = True

        logger.info("Enabled AI behavior for agent %s (%s)", agent.id, agent.role)
